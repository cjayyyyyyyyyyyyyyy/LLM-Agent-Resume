# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## ğŸš€ Project Overview
**Complete AI-Powered Resume Screening System** - A production-ready FastAPI application that intelligently screens job candidate resumes using GPT-4o and semantic vector search with ChromaDB.

## âœ… Current Status: **PRODUCTION READY**
**Development Phase**: 95% Complete (Only final system testing remaining per DEVELOPMENT_PLAN.md)

## ğŸ“¦ **Complete System Architecture**

### **Directory Structure** *(Fully Implemented)*
```
resume_screening/
â”œâ”€â”€ app/                          # âœ… Main application implementation
â”‚   â”œâ”€â”€ api/                      # âœ… REST API endpoints
â”‚   â”‚   â”œâ”€â”€ models.py            # âœ… Pydantic API models
â”‚   â”‚   â””â”€â”€ routes.py            # âœ… Complete API routes
â”‚   â”œâ”€â”€ core/                     # âœ… Complete AI pipeline
â”‚   â”‚   â”œâ”€â”€ analyzer.py           # âœ… LLM candidate analysis
â”‚   â”‚   â”œâ”€â”€ cache_manager.py      # âœ… Caching layer
â”‚   â”‚   â”œâ”€â”€ document_parser.py    # âœ… PDF/document processing
â”‚   â”‚   â”œâ”€â”€ extractor.py          # âœ… Metadata extraction
â”‚   â”‚   â”œâ”€â”€ filter.py            # âœ… Hard requirement filtering
â”‚   â”‚   â”œâ”€â”€ llm_client.py        # âœ… OpenAI integration
â”‚   â”‚   â”œâ”€â”€ query_parser.py      # âœ… Natural language parsing
â”‚   â”‚   â”œâ”€â”€ ranker.py            # âœ… Ranking algorithms
â”‚   â”‚   â”œâ”€â”€ result_formatter.py   # âœ… API response formatting
â”‚   â”‚   â”œâ”€â”€ retriever.py         # âœ… Semantic search
â”‚   â”‚   â”œâ”€â”€ scorer.py            # âœ… Multi-dimensional scoring
â”‚   â”‚   â””â”€â”€ vector_store.py      # âœ… ChromaDB management
â”‚   â”œâ”€â”€ models/                   # âœ… Data models
â”‚   â””â”€â”€ main.py                   # âœ… FastAPI entry point
â”œâ”€â”€ cache/                        # âœ… Runtime cache storage
â”œâ”€â”€ chroma_db/                    # âœ… Production vector database
â”œâ”€â”€ config/                       # âœ… Configuration management
â”œâ”€â”€ data/                         # âœ… Sample resumes (PDF format)
â”œâ”€â”€ notebooks/                    # âœ… Analysis notebooks
â”œâ”€â”€ test_chroma_db/               # âœ… Testing vector database
â”œâ”€â”€ tests/                        # âœ… Comprehensive test suite (14 test files)
â”œâ”€â”€ Dockerfile                   # âœ… Docker containerization
â”œâ”€â”€ requirements.txt             # âœ… Complete dependency list
â””â”€â”€ README.md                    # âœ… Complete documentation
```

## ğŸ”§ **Development Setup** *(Production Ready)*

### **Quick Start (1 Command)**
```bash
# Clone and run complete system
cd resume_screening && python -m venv venv && source venv/bin/activate && pip install -r requirements.txt
```

### **Configuration**
```bash
# Create .env file
cp .env.example .env
# Edit .env with your OpenAI API key:
OPENAI_API_KEY=your_openai_api_key
```

### **Run Commands**
```bash
# Development with hot reload
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000

# Production mode
uvicorn app.main:app --host 0.0.0.0 --port 8000

# Docker deployment
docker build -t resume-screening .
docker run -d -p 8000:8000 --env-file .env resume-screening
```

## ğŸ§ª **Testing Commands** *(14 Test Suites)*
```bash
# Run all tests with verbose output
python -m pytest tests/ -v

# Run specific test suites
python -m pytest tests/test_api.py -v                    # API endpoints
python -m pytest tests/test_end_to_end.py -v             # Full system flow
python -m pytest tests/test_full_system.py -v            # Real PDF testing
python -m pytest tests/test_integration.py -v            # Component integration
python -m pytest tests/test_analyzer.py -v               # LLM analysis
python -m pytest tests/test_scorer.py -v                 # Scoring algorithms

# Generate coverage report
python -m pytest tests/ --cov=app --cov-report=html
```

## ğŸ¯ **Production API Endpoints** *(Fully Implemented)*

### **Core Endpoints**
- `POST /api/v1/resumes` - Upload PDF resume with automatic parsing
- `POST /api/v1/queries` - Submit natural language screening requirements
- `GET /api/v1/results/{query_id}` - Get ranked candidate results with LLM analysis
- `GET /api/v1/resumes/{resume_id}` - Get specific resume details
- `GET /api/v1/health` - Health check

### **API Example Usage**
```python
# Upload resume
POST /api/v1/resumes
Content-Type: multipart/form-data
{ "file": resume.pdf }

# Submit query
POST /api/v1/queries
{ "query_text": "éœ€è¦5å¹´ä»¥ä¸ŠPythonç»éªŒçš„åç«¯å¼€å‘å·¥ç¨‹å¸ˆï¼Œç†Ÿæ‚‰äº‘åŸç”ŸæŠ€æœ¯ï¼ŒæœŸæœ›è–ªèµ„20-30k" }

# Get results
GET /api/v1/results/{query_id}
```

## ğŸ§  **AI Pipeline Architecture** *(Complete)*

### **End-to-End Data Flow**
1. **ğŸ“„ Document Upload** â†’ PDF parser â†’ Clean text extraction
2. **ğŸ” Metadata Extracting** â†’ GPT-4o â†’ Resume structure + skills
3. **ğŸ“Š Vector Indexing** â†’ Embeddings + ChromaDB â†’ Semantic search capabilities
4. **ğŸ¤” Query Understanding** â†’ GPT-4o â†’ Structured search criteria
5. **ğŸ” Semantic Retrieval** â†’ Vector similarity â†’ Top candidates
6. **âš™ï¸ Multi-Stage Filtering**
   - Hard conditions (experience, education, salary)
   - Soft skills matching
   - Multi-dimensional scoring algorithm
7. **ğŸ“‹ LLM Analysis** â†’ Individual candidate evaluation + recommendations
8. **ğŸ“¤ Result Formatting** â†’ API-ready structured responses

### **Scoring Dimensions**
- **Skills Matching** (0-100 points)
- **Experience Level** (0-100 points)
- **Education Alignment** (0-100 points)
- **Salary Compatibility** (0-100 points)
- **Location Preferences** (0-100 points)
- **Domain Expertise** (0-100 points)

## ğŸ“Š **Production Dependencies** *(Complete)*

```txt
# Core AI/ML Stack
faiss-cpu==1.8.0           # Vector similarity search
langchain==0.3.1          
langchain-community==0.3.1
langchain-core==0.3.6
langchain-openai==0.2.1    # OpenAI integration
openai==1.51.2

# Vector Database
chromadb==0.5.5

# Document Processing
pypdf==5.0.1              
pdfplumber==0.11.4         # Advanced PDF processing
python-multipart==0.0.12   # File upload support

# Web Framework
fastapi==0.115.0
uvicorn==0.30.6

# Data Models & Caching
pydantic==2.9.2
diskcache==5.6.3          
loguru==0.7.2             # Structured logging

# Development & Testing
pytest==8.3.3
pytest-asyncio==0.24.0
pytest-cov==5.0.0
httpx==0.27.2
```

## ğŸ³ **Docker Support** *(Complete)*

### **Dockerfile** *(Production Ready)*
```dockerfile
FROM python:3.10-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt
COPY . .
EXPOSE 8000
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### **Build & Run**
```bash
docker build -t resume-screening:latest .
docker run -d -p 8000:8000 --env-file .env resume-screening:latest
```

## âš¡ **Performance Features**
- **Caching Layer**: `app/core/cache_manager.py` reduces redundant processing
- **Concurrent API**: Async FastAPI endpoints
- **Vector Database**: Fast semantic search with ChromaDB
- **PDF Optimization**: Efficient document parsing with caching
- **Memory Management**: Proper cleanup for large document processing

## ğŸ¯ **Real-World Testing**

### **Included Test Data**
- Sample PDF resumes in `data/` directory
- Complete end-to-end processing tests
- Real GPT-4o integration tests
- ChromaDB persistence testing

### **Verification Steps**
```bash
# Test complete system flow
python -m pytest tests/test_full_system.py -v

# Test with actual PDF files
python -m pytest tests/test_end_to_end.py -v

# Verify API functionality
python -m pytest tests/test_api.py -v
```

## ğŸ” **Development Workflow** *(Updated)*

### **Current Phase**: Final System Testing (Phase 4)
1. âœ… All core modules implemented
2. âœ… All API endpoints functional
3. âœ… All 14 test suites created
4. âœ… Docker containerization complete
5. âœ… Production documentation ready
6. ğŸ”„ Final integration testing in progress

### **Next Steps**
- Run complete system validation
- Load test with real resume samples
- Performance optimization based on test results
- Production deployment preparation

---

## ğŸŒ **Environment Configuration**

### **Required Environment Variables**
```bash
OPENAI_API_KEY=sk-your-openai-key
OPENAI_BASE_URL=https://api.openai.com/v1
VECTORSTORE_COLLECTION=resume_screening
VECTORSTORE_DIRECTORY=chroma_db
CACHE_DIRECTORY=cache
LOG_LEVEL=INFO
```

### **Quick Validation**
```bash
# Test API health
curl http://localhost:8000/api/v1/health

# Test complete flow
curl -X POST http://localhost:8000/api/v1/queries -H "Content-Type: application/json" -d '{"query_text": "Software engineer with 5 years Python experience"}'
```

**Status**: Ready for production deployment with comprehensive test coverage and complete documentation.